{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":194766162,"sourceType":"kernelVersion"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Install Libraries -------------------------------------------------------------------------------------------\n!pip install torchsummary\n!pip install pytorchvideo\n\nfrom IPython import display\ndisplay.clear_output()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:04:57.067650Z","iopub.execute_input":"2024-08-31T09:04:57.068351Z","iopub.status.idle":"2024-08-31T09:05:36.540759Z","shell.execute_reply.started":"2024-08-31T09:04:57.068320Z","shell.execute_reply":"2024-08-31T09:05:36.539576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Imports ------------------------------------------------------------------------------------------------------\nimport torch\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torchsummary import summary\n\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport random\n\nimport os\nimport shutil\nimport copy\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-31T09:05:36.543244Z","iopub.execute_input":"2024-08-31T09:05:36.543731Z","iopub.status.idle":"2024-08-31T09:05:45.063937Z","shell.execute_reply.started":"2024-08-31T09:05:36.543684Z","shell.execute_reply":"2024-08-31T09:05:45.062904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nds_zip_path = '/kaggle/input/fight-detection-x3d-preprocess/data.zip'\nds_unzip_path = '/kaggle/working/data/'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'device: {DEVICE}')\n\nBATCH_SIZE = 8\nNUM_EPOCHS = 100\n\nNUM_FRAMES = 16\nFRAME_W = 256\nFRAME_H = 256\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:08.059304Z","iopub.execute_input":"2024-08-31T09:08:08.060291Z","iopub.status.idle":"2024-08-31T09:08:08.066576Z","shell.execute_reply.started":"2024-08-31T09:08:08.060257Z","shell.execute_reply":"2024-08-31T09:08:08.065605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- unzip data ---------------------------------------------------------------------------------------------------\nshutil.unpack_archive(ds_zip_path, ds_unzip_path, 'zip')\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:05:45.140319Z","iopub.execute_input":"2024-08-31T09:05:45.140667Z","iopub.status.idle":"2024-08-31T09:07:04.864027Z","shell.execute_reply.started":"2024-08-31T09:05:45.140627Z","shell.execute_reply":"2024-08-31T09:07:04.862957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to count number of samples is ds --------------------------------------------------------------------\ndef count_samples(data_dir):\n    counts = {}\n    \n    for subset in ['train', 'val', 'test']:\n        subset_path = os.path.join(data_dir, subset)\n        counts[subset] = {}\n        \n        for category in ['Violence', 'NonViolence']:\n            category_path = os.path.join(subset_path, category)\n            num_samples = len(os.listdir(category_path))\n            counts[subset][category] = num_samples\n    \n    return counts\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:04.865192Z","iopub.execute_input":"2024-08-31T09:07:04.865527Z","iopub.status.idle":"2024-08-31T09:07:04.872117Z","shell.execute_reply.started":"2024-08-31T09:07:04.865502Z","shell.execute_reply":"2024-08-31T09:07:04.871162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Dataset size -------------------------------------------------------------------------------------------------\nsample_counts = count_samples(ds_unzip_path)\n\n# Print the sample counts\nfor subset, categories in sample_counts.items():\n    print(f\"{subset} set:\")\n    for category, count in categories.items():\n        print(f\"  {category}: {count} samples\")\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:04.873324Z","iopub.execute_input":"2024-08-31T09:07:04.873736Z","iopub.status.idle":"2024-08-31T09:07:04.891089Z","shell.execute_reply.started":"2024-08-31T09:07:04.873707Z","shell.execute_reply":"2024-08-31T09:07:04.890077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Dataset class for loading the videos ------------------------------------------------------------------------\nclass VideoDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['Violence', 'NonViolence']\n        self.frame_paths = []\n        self.labels = []\n\n        for label, class_name in enumerate(self.classes):\n            class_dir = os.path.join(root_dir, class_name)\n            for frame_file in os.listdir(class_dir):\n                frame_path = os.path.join(class_dir, frame_file)\n                self.frame_paths.append(frame_path)\n                self.labels.append(label)\n\n    def __len__(self):\n        return len(self.frame_paths)\n\n    def __getitem__(self, idx):\n        frame_path = self.frame_paths[idx]\n        label = self.labels[idx]\n\n        frames = np.load(frame_path)\n\n        if self.transform:\n            frames = self.transform(frames)\n\n        return frames, label\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:04.929092Z","iopub.execute_input":"2024-08-31T09:07:04.929451Z","iopub.status.idle":"2024-08-31T09:07:05.061796Z","shell.execute_reply.started":"2024-08-31T09:07:04.929417Z","shell.execute_reply":"2024-08-31T09:07:05.060993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Class To Convert Frames to normalized Tensors ---------------------------------------------------------------\nclass ToTensor(object):\n    def __call__(self, sample):\n        frames = sample\n        \n        #-- Convert to Tensor (C, T, H, W) --\n        frames = frames.transpose((3, 0, 1, 2))\n        frames = torch.from_numpy(frames).float()\n\n        #-- Normalize --\n        frames = frames / 255.0\n        return frames\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:05.063230Z","iopub.execute_input":"2024-08-31T09:07:05.063846Z","iopub.status.idle":"2024-08-31T09:07:05.082508Z","shell.execute_reply.started":"2024-08-31T09:07:05.063790Z","shell.execute_reply":"2024-08-31T09:07:05.081166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Load Data ----------------------------------------------------------------------------------------------------\n#-- Set the paths to dataset --\ntrain_dir = ds_unzip_path + 'train'\nval_dir = ds_unzip_path + 'val'\ntest_dir = ds_unzip_path + 'test'\n\n\n#-- Data transformations --\ndata_transforms = {\n    'train': transforms.Compose([ToTensor()]),\n    'val': transforms.Compose([ToTensor()]),\n    'test': transforms.Compose([ToTensor()]),\n}\n\n#-- Create datasets for train, val, and test --\ntrain_dataset = VideoDataset(root_dir=train_dir, transform=data_transforms['train'])\nval_dataset = VideoDataset(root_dir=val_dir, transform=data_transforms['val'])\ntest_dataset = VideoDataset(root_dir=test_dir, transform=data_transforms['test'])\n\n#-- Create DataLoaders --\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:19.203222Z","iopub.execute_input":"2024-08-31T09:08:19.204097Z","iopub.status.idle":"2024-08-31T09:08:19.220352Z","shell.execute_reply.started":"2024-08-31T09:08:19.204063Z","shell.execute_reply":"2024-08-31T09:08:19.219527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Check Data Loaders -------------------------------------------------------------------------------------------\nfor i, (videos, labels) in enumerate(train_loader):\n        print(videos.shape, labels.shape)\n        break\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:28.237500Z","iopub.execute_input":"2024-08-31T09:08:28.238209Z","iopub.status.idle":"2024-08-31T09:08:29.198750Z","shell.execute_reply.started":"2024-08-31T09:08:28.238176Z","shell.execute_reply":"2024-08-31T09:08:29.197768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Modify X3D for finetuning ------------------------------------------------------------------------\ndef custome_X3D(num_classes):\n    #-- load X3D model --\n    model_name = 'x3d_m'\n    model = torch.hub.load('facebookresearch/pytorchvideo', model_name, pretrained=True)   \n    \n    #-- set last layer for custome classification --\n    input_size = model.blocks[-1].proj.in_features\n    model.blocks[-1].proj = nn.Linear(in_features=input_size, out_features=num_classes)\n\n    return model\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:32.828310Z","iopub.execute_input":"2024-08-31T09:08:32.828748Z","iopub.status.idle":"2024-08-31T09:08:32.835374Z","shell.execute_reply.started":"2024-08-31T09:08:32.828711Z","shell.execute_reply":"2024-08-31T09:08:32.834364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Train Model --------------------------------------------------------------------------------------\ndef train(model, loader, optimizer, criterion):\n    model.train()\n    \n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for videos, labels in loader:\n        \n        videos, labels = videos.to(DEVICE), labels.to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(videos)       \n        \n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n\n    loss = running_loss / len(loader)\n    accuracy = correct / total\n    return loss , accuracy\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:35.474180Z","iopub.execute_input":"2024-08-31T09:08:35.474849Z","iopub.status.idle":"2024-08-31T09:08:35.483229Z","shell.execute_reply.started":"2024-08-31T09:08:35.474814Z","shell.execute_reply":"2024-08-31T09:08:35.482219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Evaluate Model -----------------------------------------------------------------------------------\ndef evaluate(model, loader, criterion):\n    model.eval()\n    \n    correct = 0\n    total = 0\n    running_loss = 0.0\n\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    loss = running_loss / len(loader)\n    acc = correct / total\n    return loss , acc\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:38.132637Z","iopub.execute_input":"2024-08-31T09:08:38.133600Z","iopub.status.idle":"2024-08-31T09:08:38.141771Z","shell.execute_reply.started":"2024-08-31T09:08:38.133553Z","shell.execute_reply":"2024-08-31T09:08:38.140517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #-- Create and Initialize Model and its Params -------------------------------------------------------------------\nnum_classes = 2  # For Fighting and Normal\nmodel = custome_X3D(num_classes).to(DEVICE)\n\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n# #-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:08:42.122914Z","iopub.execute_input":"2024-08-31T09:08:42.123726Z","iopub.status.idle":"2024-08-31T09:08:46.104902Z","shell.execute_reply.started":"2024-08-31T09:08:42.123688Z","shell.execute_reply":"2024-08-31T09:08:46.104077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Display the model summary ------------------------------------------------------------------------------------\nsummary(model, input_size=(3,16,256,256), device=DEVICE.type, batch_size=-1)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:10:37.760072Z","iopub.execute_input":"2024-08-31T09:10:37.760854Z","iopub.status.idle":"2024-08-31T09:10:37.924334Z","shell.execute_reply.started":"2024-08-31T09:10:37.760814Z","shell.execute_reply":"2024-08-31T09:10:37.923293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Train Model -------------------------------------------------------------------------------------------------\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\n\nbest_model = None\nbest_acc = 0\n\nfor epoch in range(NUM_EPOCHS):\n    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = evaluate(model, val_loader, criterion)    \n    \n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    \n    if val_acc> best_acc:\n        best_acc = val_acc\n        best_model = copy.deepcopy(model)\n        \n    \n    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, '\n          f'Train Loss: {train_loss:.4f}, Train ACC: {train_acc:.4f}, '\n          f'Val Loss: {val_loss:.4f}, Val ACC: {val_acc:.4f}')\n    \nlast_model = copy.deepcopy(model)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:10:45.472142Z","iopub.execute_input":"2024-08-31T09:10:45.472515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Plot ACC and Loss --------------------------------------------------------------------------------------------\nepochs = range(1, NUM_EPOCHS + 1)\n\nplt.figure(figsize=(14, 5))\n\n# Plot training & validation loss\nplt.subplot(1, 2, 1)\nplt.plot(epochs, train_losses, 'bo-', label='Train Loss')\nplt.plot(epochs, val_losses, 'ro-', label='Val Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot training & validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(epochs, train_accuracies, 'bo-', label='Train Accuracy')\nplt.plot(epochs, val_accuracies, 'ro-', label='Val Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:05.495835Z","iopub.status.idle":"2024-08-31T09:07:05.496188Z","shell.execute_reply.started":"2024-08-31T09:07:05.496017Z","shell.execute_reply":"2024-08-31T09:07:05.496032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #--Evaluate Model On Test Data --------------------------------------------------------------------------------\ntest_loss, test_acc = evaluate(best_model, test_loader, criterion)\nprint(f'Final Test Accuracy: {test_acc:.4f}')\n# #---------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:05.497227Z","iopub.status.idle":"2024-08-31T09:07:05.497627Z","shell.execute_reply.started":"2024-08-31T09:07:05.497410Z","shell.execute_reply":"2024-08-31T09:07:05.497426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Compare Last Model and Best Model ----------------------------------------------------------------------------\n\n#-- last model --\ntrain_loss, train_acc = evaluate(last_model, train_loader, criterion)   \nval_loss, val_acc = evaluate(last_model, val_loader, criterion)   \ntest_loss, test_acc = evaluate(last_model, test_loader, criterion)\n\nprint('Last Weights:\\n'\n         f'Train Loss: {train_loss: .4f} - Train ACC: {train_acc: .4f}\\n'\n         f'Val Loss: {val_loss: .4f} - Val ACC: {val_acc: .4f}\\n'\n         f'Test Loss: {test_loss: .4f} - Test ACC: {test_acc: .4f}')\n\n#-- best model --\ntrain_loss, train_acc = evaluate(best_model, train_loader, criterion)   \nval_loss, val_acc = evaluate(best_model, val_loader, criterion)   \ntest_loss, test_acc = evaluate(best_model, test_loader, criterion)\n\nprint('\\n\\nBest Weights:\\n'\n         f'Train Loss: {train_loss: .4f} - Train ACC: {train_acc: .4f}\\n'\n         f'Val Loss: {val_loss: .4f} - Val ACC: {val_acc: .4f}\\n'\n         f'Test Loss: {test_loss: .4f} - Test ACC: {test_acc: .4f}')\n#----------------------------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-08-31T09:07:05.498847Z","iopub.status.idle":"2024-08-31T09:07:05.499212Z","shell.execute_reply.started":"2024-08-31T09:07:05.499034Z","shell.execute_reply":"2024-08-31T09:07:05.499050Z"},"trusted":true},"execution_count":null,"outputs":[]}]}