{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":397693,"sourceType":"datasetVersion","datasetId":176381}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Install Libraries -------------------------------------------------------------------------------------------\n# !pip install torchsummary\n!pip install pytorchvideo\n\nfrom IPython import display\ndisplay.clear_output()\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Imports ------------------------------------------------------------------------------------------------------\nimport torch\n\n# import torch.nn as nn\n# import torch.nn.functional as F\n# import torch.optim as optim\n# from torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom sklearn.model_selection import train_test_split\n\n# from torchsummary import summary\n\nimport cv2\n# import matplotlib.pyplot as plt\n\nimport numpy as np\nimport random\n\nimport os\nimport shutil\nimport copy\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Initialize ---------------------------------------------------------------------------------------------------\nds_input_path = '/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/'\n\nds_preprocessed_path = '/kaggle/working/ds/'\ntrain_path = ds_preprocessed_path + 'train'\nval_path = ds_preprocessed_path + 'val'\ntest_path = ds_preprocessed_path + 'test'\n\nNUM_FRAMES = 16\nFRAME_W = 256\nFRAME_H = 256\n\nCLASS_NAMES = ['Violence', 'NonViolence']\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Create Folders  ----------------------------------------------------------------------------------------------\nos.makedirs(train_path, exist_ok=True)\nos.makedirs(val_path, exist_ok=True)\nos.makedirs(test_path, exist_ok=True)\n#-----------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Check Number of Frames and Resolution of Videos ------------------------------------------------------------\ni = 0\nfor root, dirs, files in os.walk(ds_input_path):\n    \n    for filename in files:\n        file_path = os.path.join(root, filename)   \n        \n        if file_path.endswith(('.mp4')):          \n            cap = cv2.VideoCapture(file_path)        \n\n            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\n            num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n            print(f\"Video: {filename} | number of frames: {num_frames} - Resolution: {width} x {height}\")\n\n            # Release the video capture object\n            cap.release()\n            \n            i += 1\n            \n            if i>=10:\n                break\n#-------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Function to Preprocess videos -------------------------------------------------------------------------------\ndef preprocess_video(video_path, output_path, num_frames=NUM_FRAMES, resize=(FRAME_W, FRAME_H)):    \n    \n    cap = cv2.VideoCapture(video_path)\n    frames = []\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        frame = cv2.resize(frame, resize)\n        frames.append(frame)\n    cap.release()\n\n    frames = np.array(frames)\n\n    #-- Sample frames --\n    if len(frames) > num_frames:\n        indices = np.linspace(0, len(frames) - 1, num_frames).astype(int)\n        sampled_frames = frames[indices]\n    elif len(frames) < num_frames:\n        padding = np.zeros((num_frames - len(frames), *resize, 3))\n        sampled_frames = np.concatenate((frames, padding), axis=0)\n    else:\n        sampled_frames = frames\n    \n    #-- Save preprocessed frames --\n    np.save(output_path, sampled_frames)\n#-------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Preprocees and Split Data ------------------------------------------------------------------------------------\ndef split_and_preprocess_videos(input_folder, train_dir, val_dir, test_dir, frame_size):\n    \n    #-- Create output directories if they don't exist --\n    for dir in [train_dir, val_dir, test_dir]:\n        os.makedirs(dir, exist_ok=True)\n\n    for class_name in CLASS_NAMES:\n        class_folder = os.path.join(input_folder, class_name)\n       \n        #-- Get all video files in the class folder --\n        videos = [f for f in os.listdir(class_folder) if f.endswith(('.mp4', '.avi', '.mov'))]\n        \n        #-- Split into train, val, test --\n        train_videos, temp_videos = train_test_split(videos, test_size=0.2, random_state=42)\n        val_videos, test_videos = train_test_split(temp_videos, test_size=0.5, random_state=42)\n        \n        splits = {'train': train_videos, 'val': val_videos, 'test': test_videos}\n        \n        for split in splits:\n            split_folder = os.path.join(train_dir if split == 'train' else val_dir if split == 'val' else test_dir, class_name)\n            os.makedirs(split_folder, exist_ok=True)\n            \n            for video in splits[split]:\n                video_path = os.path.join(class_folder, video)\n                output_path = os.path.join(split_folder, video.replace('.mp4', '.npy'))\n                preprocess_video(video_path, output_path, NUM_FRAMES, frame_size)\n                print(f'Processed and saved {video} to {split_folder}')\n#-------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Run the preprocessing and splitting --\nsplit_and_preprocess_videos(input_folder= ds_input_path,\n                            train_dir= train_path,\n                            val_dir= val_path,\n                            test_dir= test_path,\n                            frame_size = (FRAME_W, FRAME_H))\n#-------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-- Zip Data -----------------------------------------------------------------------------------------------------\nds_zip_file = '/kaggle/working/data'\nshutil.make_archive(ds_zip_file, 'zip', ds_preprocessed_path)\nshutil.rmtree(ds_preprocessed_path)\n#-------------------------------------------------------------------------------------------------------------","metadata":{},"execution_count":null,"outputs":[]}]}